from typing import Dict, Any, List
from langgraph.types import interrupt
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate 

from ..state import ProjectState
from ..config import get_llm


# --- MODELO DE DATOS PARA LA DECISI√ìN DEL CHAT ---
class ChatDecision(BaseModel):
    """
    Clasifica la intenci√≥n del usuario y extrae la informaci√≥n necesaria.
    """
    response: str = Field(description="La respuesta conversacional directa a la pregunta del usuario.")
    action: str = Field(
        description="La acci√≥n a seguir. Debe ser una de: 'continue' (para seguir chateando), 'find_funding' (para buscar financiaci√≥n), 'specific_report' (para generar un reporte de una oportunidad), o 'end' (para finalizar)."
    )
    target_index: int = Field(
        default=None, 
        description="Si la acci√≥n es 'specific_report', este es el √≠ndice num√©rico de la oportunidad mencionada por el usuario."
    )


def select_opportunities(state: ProjectState) -> Dict[str, Any]:
    """
    Nodo que presenta las oportunidades de la √öLTIMA b√∫squeda.
    ‚úÖ Ahora solo muestra las oportunidades nuevas, no todo el historial.
    """
    print("\n" + "="*80)
    print("NODO: PRESENTAR Y PAUSAR PARA SELECCI√ìN DE OPORTUNIDADES")
    print("="*80)
    
    # ‚úÖ Obtener SOLO las oportunidades de la √∫ltima b√∫squeda
    current_opportunities = state.get("investment_opportunities", [])
    
    if not current_opportunities:
        print("   -> No hay nuevas oportunidades para seleccionar.")
        return {
            "user_selection": "none",
            "investment_opportunities": []
        }
    
    print(f"\n   Se encontraron {len(current_opportunities)} nuevas oportunidades.")
    print("   Pausando ejecuci√≥n para esperar selecci√≥n del usuario...\n")
    
    opportunities_info = {
        "total_opportunities": len(current_opportunities),
        "opportunities": [
            {
                "index": idx,
                "origin": opp.get("origin", "N/A"),
                "description": opp.get("description", "N/A"),
                "financing_type": opp.get("financing_type", "N/A"),
                "application_deadline": opp.get("application_deadline", "N/A"),
                "opportunity_url": opp.get("opportunity_url", "N/A")
            }
            for idx, opp in enumerate(current_opportunities)
        ],
        "instruction": "Por favor, selecciona las oportunidades que deseas analizar. "
                      "Env√≠a una lista de √≠ndices (ej: [0, 1, 2]) o 'all' para seleccionar todas."
    }
    
    return {
        "user_selection": interrupt(opportunities_info),
        "investment_opportunities": current_opportunities
    }


def process_selection(state: ProjectState) -> Dict[str, Any]:
    """
    Procesa la selecci√≥n del usuario.
    ‚úÖ Las seleccionadas se A√ëADEN a las ya existentes (acumulaci√≥n).
    """
    print("\n" + "="*80)
    print("NODO: PROCESANDO SELECCI√ìN DEL USUARIO")
    print("="*80)

    user_selection = state.get("user_selection")
    # ‚úÖ Oportunidades de la √∫ltima b√∫squeda
    current_opportunities = state.get("investment_opportunities", [])
    # ‚úÖ Oportunidades YA seleccionadas previamente
    previously_selected = state.get("selected_opportunities", [])
    
    newly_selected = []

    if user_selection == "none":
        print("   -> No hay oportunidades nuevas.")
        message_content = "No se encontraron nuevas oportunidades en esta b√∫squeda."

    elif isinstance(user_selection, str) and user_selection.lower() == "all":
        newly_selected = current_opportunities
        print(f"   ‚úÖ Usuario seleccion√≥ TODAS las nuevas oportunidades ({len(newly_selected)})")
        message_content = f"Has seleccionado {len(newly_selected)} nuevas oportunidades para an√°lisis."

    elif isinstance(user_selection, list):
        valid_indices = [
            idx for idx in user_selection 
            if isinstance(idx, int) and 0 <= idx < len(current_opportunities)
        ]
        newly_selected = [current_opportunities[idx] for idx in valid_indices]
        print(f"   ‚úÖ Usuario seleccion√≥ {len(newly_selected)} oportunidades: {valid_indices}")
        message_content = f"Has seleccionado {len(newly_selected)} nuevas oportunidades para an√°lisis."
        
    else:
        print(f"   ‚ö†Ô∏è Selecci√≥n inv√°lida: {user_selection}")
        message_content = "Selecci√≥n inv√°lida. No se a√±adieron oportunidades."

    # ‚úÖ ACUMULAR: Combinar las previamente seleccionadas con las nuevas
    total_selected = previously_selected + newly_selected
    
    print(f"\n   üìä Total acumulado de oportunidades seleccionadas: {len(total_selected)}\n")

    return {
        "selected_opportunities": total_selected,  # ‚úÖ Acumulaci√≥n
        "user_selection": None,
        "investment_opportunities": [],  # ‚úÖ Limpiar las de la b√∫squeda actual
        "messages": [{
            "role": "assistant", 
            "content": f"{message_content}\n\nTotal acumulado para an√°lisis: {len(total_selected)} oportunidades."
        }]
    }


def chat_responder(state: ProjectState) -> Dict[str, Any]:
    """
    Nodo interactivo del chat.
    ‚úÖ Ahora reporta correctamente el historial completo.
    """
    print("\n" + "="*80)
    print("NODO: CHAT INTERACTIVO (Centro de Comando)")
    print("="*80)
    
    # ‚úÖ Mostrar informaci√≥n del historial completo
    total_history = len(state.get("all_opportunities_history", []))
    total_selected = len(state.get("selected_opportunities", []))
    
    user_input = interrupt({ 
        "status": "ready", 
        "instruction": "Env√≠a tu pregunta o comando.",
        "current_state": {
            "total_opportunities_found": total_history,  # ‚úÖ Historial completo
            "selected_for_analysis": total_selected,
            "academic_papers": len(state.get("academic_papers", [])),
            "reports_generated": len(state.get("report_paths", []))
        }
    })
    
    question = str(user_input)
    print(f"\n   ‚û°Ô∏è Procesando entrada: {question[:80]}...")
    
    llm = get_llm()
    parser = JsonOutputParser(pydantic_object=ChatDecision)

    # ‚úÖ Formatear el HISTORIAL COMPLETO para el prompt
    all_history = state.get("all_opportunities_history", [])
    opportunities_summary = "\n".join([
        f"√çndice {idx}: {opp.get('origin', 'N/A')} - {opp.get('description', 'N/A')[:100]}..."
        for idx, opp in enumerate(all_history)
    ]) if all_history else "No hay oportunidades en el historial a√∫n."

    system_prompt ="""
    **Tu Rol:** Eres un dispatcher de intenciones. Tu √∫nica funci√≥n es analizar el input del usuario y clasificarlo en una acci√≥n espec√≠fica. Eres extremadamente preciso.

    **Acciones V√°lidas:**
    1.  `find_funding`: Dispara una NUEVA b√∫squeda de oportunidades de financiaci√≥n. Se activa con frases como:
        - "Busca financiaci√≥n para el proyecto"
        - "Encuentra nuevas oportunidades"
        - "Investiga opciones de grants"
        - "Necesito m√°s alternativas de inversi√≥n"
    2.  `specific_report`: Dispara la generaci√≥n de un reporte para UNA oportunidad ya existente en el historial. Se activa con frases que mencionan un √≠ndice o un nombre de oportunidad.
        - "Analiza la oportunidad 0"
        - "Dame un reporte sobre la de Minciencias"
        - "Profundiza en la segunda opci√≥n"
    3.  `continue`: Para CUALQUIER OTRA PREGUNTA. Si el usuario pide un resumen, pregunta "qu√© oportunidades hay", o simplemente conversa, la acci√≥n es 'continue'.
    4.  `end`: Si el usuario quiere terminar la sesi√≥n ("adi√≥s", "fin", "terminar").

    **Contexto (Historial de Oportunidades Encontradas):**
    {opportunities_summary}

    **Tarea:**
    1.  Analiza la pregunta del usuario: `{question}`
    2.  Determina la **acci√≥n** correcta seg√∫n las reglas de arriba.
    3.  Si la acci√≥n es `specific_report`, extrae el **√≠ndice num√©rico** correspondiente.
    4.  Genera una **respuesta** conversacional corta que confirme la acci√≥n.
    5.  Devuelve un objeto JSON con el formato exacto.

    **Ejemplos de Decisi√≥n:**

    - Usuario: "¬øQu√© oportunidades hemos encontrado hasta ahora?"
      - Acci√≥n: `continue` (Es una pregunta, no un comando de acci√≥n)
      - JSON: {{{{ "response": "Hasta ahora, hemos encontrado las siguientes oportunidades...", "action": "continue", "target_index": null }}}}

    - Usuario: "investiga nuevas oportunidades de financiamiento"
      - Acci√≥n: `find_funding` (Es un comando de acci√≥n expl√≠cito)
      - JSON: {{{{ "response": "Entendido. Iniciando una nueva b√∫squeda de oportunidades de financiaci√≥n.", "action": "find_funding", "target_index": null }}}}

    - Usuario: "Analiza la oportunidad con √≠ndice 1, por favor."
      - Acci√≥n: `specific_report` (Comando de acci√≥n con un objetivo claro)
      - JSON: {{{{ "response": "Claro, generando un an√°lisis detallado para la oportunidad 1.", "action": "specific_report", "target_index": 1 }}}}

    {{format_instructions}}
"""
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{{question}}")
    ])
    
    chain = prompt | llm | parser

    try:
        decision = chain.invoke({
            "question": question,
            "opportunities_summary": opportunities_summary,
            "total_history": total_history,
            "total_selected": total_selected,
            "format_instructions": parser.get_format_instructions()
        })
        
        action = decision.get("action", "continue")
        target_index = decision.get("target_index")
        
        print(f"   ‚úÖ Decisi√≥n del LLM: Acci√≥n='{action}', √çndice='{target_index}'")
        
        return {
            "messages": [
                HumanMessage(content=question),
                {"role": "assistant", "content": decision.get("response")}
            ],
            "next_action": action,
            "action_input": target_index,
            "all_opportunities_history": all_history,
            "selected_opportunities": state.get("selected_opportunities", []),
            "academic_papers": state.get("academic_papers", []),
            "report_paths": state.get("report_paths", []),
        }

    except Exception as e:
        print(f"   ‚ö†Ô∏è Error: {e}")
        return {
            "messages": [
                HumanMessage(content=question),
                {"role": "assistant", "content": f"Error: {e}"}
            ],
            "next_action": "continue",
            "all_opportunities_history": all_history,
            "selected_opportunities": state.get("selected_opportunities", []),
        }

        
# --- ROUTER INTELIGENTE ---
def route_chat(state: ProjectState) -> str:
    """
    Lee el campo 'next_action' del estado para decidir a d√≥nde ir.
    """
    action = state.get("next_action", "continue")
    print(f"\n--- ROUTER: Decidiendo la ruta basada en la acci√≥n '{action}' ---")
    
    if action == "find_funding": 
        return "find_funding"
    elif action == "specific_report":
        return "specific_report"
    elif action == "end":
        return "end"
    else:  # Por defecto o si es 'continue'
        return "continue"