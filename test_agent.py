# test_agent.py (versiÃ³n final corregida)

import httpx
import asyncio
import json
from typing import Dict, Any, List

# --- ConfiguraciÃ³n ---
LANGGRAPH_API_URL = "http://127.0.0.1:2024" 
ASSISTANT_ID = "agent"

# --- MÃ³dulo de Cliente API ---
class LangGraphClient:
    def __init__(self, base_url: str):
        self.base_url = base_url

    async def create_thread(self) -> str | None:
        async with httpx.AsyncClient() as client:
            try:
                print(f"   Conectando a {self.base_url}/threads...")
                response = await client.post(f"{self.base_url}/threads", json={}) 
                response.raise_for_status()
                print("   âœ… ConexiÃ³n exitosa.")
                return response.json()["thread_id"]
            except httpx.ConnectError as e:
                print(f"âŒ Error de conexiÃ³n al crear el thread: {e}")
                print("   AsegÃºrate de que el servidor 'langgraph dev' estÃ¡ corriendo.")
                return None
            except httpx.RequestError as e:
                print(f"âŒ Error en la peticiÃ³n al crear el thread: {e}")
                return None

    async def stream_run(self, thread_id: str, payload: Dict[str, Any]):
        url = f"{self.base_url}/threads/{thread_id}/runs/stream"
        try:
            async with httpx.AsyncClient(timeout=None) as client:
                async with client.stream("POST", url, json=payload) as response:
                    response.raise_for_status()
                    event_type = None
                    async for line in response.aiter_lines():
                        if line.startswith('event:'):
                            event_type = line.replace('event: ', '').strip()
                        elif line.startswith('data:'):
                            if not event_type: continue
                            try:
                                data_str = line[len('data: '):]
                                data = json.loads(data_str)
                                yield {"event": event_type, "data": data}
                                event_type = None 
                            except json.JSONDecodeError:
                                continue
        except httpx.HTTPStatusError as e:
            # Manejo de error mejorado para leer el cuerpo de la respuesta
            error_details = await e.response.aread()
            print(f"âŒ Error en la API de LangGraph: {e.response.status_code}")
            print(f"   Detalles: {error_details.decode()}")
        except httpx.RequestError as e:
            print(f"âŒ Error de conexiÃ³n al hacer stream del run: {e}")

# --- MÃ³dulo de UI (sin cambios) ---
def display_opportunities(interrupt_data: Dict[str, Any]):
    print("\n" + "="*70)
    print("âš ï¸  ACCIÃ“N REQUERIDA: SELECCIÃ“N DE OPORTUNIDADES")
    print("="*70)
    opportunities = interrupt_data.get('opportunities', [])
    for opp in opportunities:
        print(f"\n  [{opp['index']}] {opp['origin']}")
        print(f"      ğŸ“‹ {opp.get('description', 'N/A')[:80]}...")
    print("\n" + "="*70)
    print(interrupt_data.get('instruction'))
    print("="*70)

def get_opportunity_selection(total_opportunities: int) -> List[int] | str:
    while True:
        user_input_str = input("\nğŸ‘‰ Tu selecciÃ³n (ej: 0,1 o 'all'): ")
        if user_input_str.lower().strip() == 'all':
            return 'all'
        try:
            indices = [int(i.strip()) for i in user_input_str.split(',')]
            if all(0 <= idx < total_opportunities for idx in indices):
                return indices
            else:
                print("âŒ Uno o mÃ¡s Ã­ndices estÃ¡n fuera de rango. Intenta de nuevo.")
        except ValueError:
            print("âŒ Entrada invÃ¡lida. Usa nÃºmeros separados por comas o 'all'.")

def display_chat_prompt(interrupt_data: Dict[str, Any]):
    print("\n" + "="*70)
    print("ğŸ’¬ MODO CHAT INTERACTIVO ACTIVADO")
    print("="*70)
    print(f"\n{interrupt_data.get('message', 'El reporte estÃ¡ listo.')}\n")
    if topics := interrupt_data.get('topics'):
        print("ğŸ“š Puedes preguntar sobre:")
        for topic in topics: print(f"   â€¢ {topic}")
    print("\n" + "="*70)
    print(interrupt_data.get('instruction', "EnvÃ­a tu pregunta o 'end' para finalizar."))

# --- LÃ³gica Principal (con el payload corregido) ---
async def main():
    print("ğŸš€ Cliente AsÃ­ncrono para Agente CTM ğŸš€")
    client = LangGraphClient(LANGGRAPH_API_URL)

    print("1. Creando nuevo thread...")
    thread_id = await client.create_thread()
    if not thread_id: return
    print(f"   âœ… Thread creado: {thread_id}\n")

    print("2. Usando el proyecto de ejemplo 'AquaGuard AI'...")
    project_title = "AquaGuard AI: Sistema Predictivo de Monitoreo de Calidad del Agua con IoT y DetecciÃ³n de PatÃ³genos"
    project_description = """El proyecto "AquaGuard AI" propone el desarrollo de una red de monitoreo de agua en tiempo real para la detecciÃ³n temprana de contaminantes y la predicciÃ³n de eventos de riesgo para la salud pÃºblica. La soluciÃ³n estÃ¡ diseÃ±ada para ser desplegada en fuentes de agua crÃ­ticas como rÃ­os, embalses y lagos que abastecen a centros urbanos. La arquitectura se basa en boyas con sensores IoT, una plataforma en la nube y un motor de IA que utiliza redes neuronales recurrentes para anÃ¡lisis de series temporales y detecciÃ³n de anomalÃ­as. El objetivo es predecir la proliferaciÃ³n de algas nocivas y estimar la probabilidad de presencia de patÃ³genos, permitiendo a las autoridades tomar medidas preventivas."""
    print(f"   - TÃ­tulo: {project_title}")
    print(f"   - DescripciÃ³n: {project_description.strip()[:100]}...\n")
    
    # --- *** LA CORRECCIÃ“N ESTÃ AQUÃ *** ---
    payload = {
        "assistant_id": ASSISTANT_ID,
        "input": {
            "project_title": project_title,
            "project_description": project_description,
            "messages": [], # <-- AÃ‘ADIDO EL CAMPO OBLIGATORIO
        },
    }

    while True:
        print("\n--- â–¶ï¸  Ejecutando agente (esperando eventos en tiempo real) ---")
        interrupted = False
        async for event in client.stream_run(thread_id, payload):
            interrupted = True # Si recibimos CUALQUIER evento, sabemos que la ejecuciÃ³n no ha terminado
            if event["event"] == "values" and "messages" in event["data"]:
                last_message = event["data"]["messages"][-1]
                if isinstance(last_message, dict) and last_message.get('role') == 'assistant':
                    print(f"   ğŸ¤– Agente: {last_message['content']}")

            if event["event"] == "interrupt":
                interrupt_data = event["data"][0]["value"]
                if "opportunities" in interrupt_data:
                    display_opportunities(interrupt_data)
                    selection = get_opportunity_selection(interrupt_data.get("total_opportunities", 0))
                    payload = {"command": {"resume": selection}}
                    break
                elif "topics" in interrupt_data:
                    display_chat_prompt(interrupt_data)
                    question = input("\nğŸ’­ Tu pregunta: ")
                    if question.lower().strip() in ["end", "salir", "fin"]:
                        print("\nğŸ‘‹ Finalizando sesiÃ³n.")
                        return
                    payload = {"command": {"resume": question}}
                    break
        
        if not interrupted:
            print("\n" + "="*70)
            print("âœ… EJECUCIÃ“N DEL AGENTE COMPLETADA")
            print("="*70)
            break

if __name__ == "__main__":
    asyncio.run(main())